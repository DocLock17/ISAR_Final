{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModularAbstractionTransferSuiteBV1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ynM5BeDfWQvH",
        "n1EFy_NoE7Wl",
        "BGIl3BKliih1",
        "HNp06xZqiWKD",
        "tdX2lI15iCvS",
        "0vtDg55hojmL",
        "1F5PijpNi9Wg",
        "8z5loBrJiHON",
        "x8r9t3hNQCf3"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMYOojV5IwzXsDw6XKyh5Dh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DocLock17/ISAR_Final/blob/main/ModularAbstractionTransferSuiteBV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXiHbkQgfw9a"
      },
      "source": [
        "# Modular Abstraction Transfer Suite\n",
        "\n",
        "### A Deep Mind Based Experimental Platform For Reasearch In Abstaction And Generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynM5BeDfWQvH"
      },
      "source": [
        "#### Interactive Playgound (run after notebook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrFuoAxKQclk"
      },
      "source": [
        "# # # Run From Top (Hint: It must be loaded commented first)\n",
        "# myPlayground()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1EFy_NoE7Wl"
      },
      "source": [
        "#### Selector Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-9mrlfuSA23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616c256d-e287-482a-b28d-5878d3d19304"
      },
      "source": [
        "##   Game Selector\n",
        "ENVIRONMENT_NAME = 'BreakoutNoFrameskip-v4' #@param ['Atlantis-v0', 'DemonAttack-v0', 'Phoenix-v0', 'Riverraid-v0', 'Solaris-v0', 'Asterix-v0', 'Breakout-v0', 'Boxing-v0', 'Pong-v0', 'BattleZone-v0', 'SpaceInvaders-v0', 'BeamRider-v0','AtlantisNoFrameskip-v4', 'DemonAttackNoFrameskip-v4', 'PhoenixNoFrameskip-v4', 'RiverraidNoFrameskip-v4', 'SolarisNoFrameskip-v4', 'AsterixNoFrameskip-v4', 'BreakoutNoFrameskip-v4', 'BoxingNoFrameskip-v4', 'PongNoFrameskip-v4', 'BattleZoneNoFrameskip-v4', 'SpaceInvadersNoFrameskip-v4', 'BeamRiderNoFrameskip-v4']\n",
        "\n",
        "# Render gameplay in cell or viewer\n",
        "RENDER = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Slow down game play and discontinue training for observation\n",
        "OBSERVATION_MODE = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Display Text Output to Observe Activations and Q Updates\n",
        "DIAGNOSTIC_MODE = False #@param {type:\"boolean\"}\n",
        "\n",
        "## Chippie the Progress Bot Settings       (Name courtesy of: Kylie Locker)\n",
        "CHIPPIE_PROGESS_REPORTS = True #@param {type:\"boolean\"}\n",
        "# Row for progress bot stacking ( 1, 8, 12 )\n",
        "MAX_CHIPPIES_ROW = 8 #@param {type:\"integer\"}\n",
        "\n",
        "# Provide GPU information\n",
        "USE_GPU_SUPPORT = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "## Data Settings\n",
        "# Import and Unzip Hosted Dataset\n",
        "CREATE_MISSING_DIRECTORIES = True #@param {type:\"boolean\"}\n",
        "IMPORT_MAIN_DATA = True #@param {type:\"boolean\"}\n",
        "IMPORT_SENTIMENT_DATA = True #@param {type:\"boolean\"}\n",
        "IMPORT_MODEL_DATA = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "## Agent Settings\n",
        "# Parameters\n",
        "n_episodes = 25000 #@param {type:\"integer\"}\n",
        "BATCH_SIZE =  32#@param {type:\"integer\"}\n",
        "action_steps =  4#@param {type:\"integer\"}\n",
        "skip_start = 1 #@param {type:\"integer\"}\n",
        "agent_gamma = 0.985 #@param {type:\"slider\", min:0, max:1, step:0.0001}\n",
        "agent_epsilon = 1.0 #@param {type:\"slider\", min:0, max:1, step:0.0001}\n",
        "agent_epsilon_decay = 0.9999 #@param {type:\"slider\", min:0.5, max:1.000, step:0.0001}\n",
        "agent_epsilon_min = 0.1 #@param {type:\"slider\", min:0, max:1.000, step:0.0001}\n",
        "agent_learning_rate = 0.00025 #@param {type:\"number\", min:0.0000, max:0.0200, step:0.00001}\n",
        "# lr=0.00042 # lr=0.00125 #lr=0.00025\n",
        "\n",
        "## Buffer Settings\n",
        "STARTING_MEMORY_SIZE = 25000#@param {type:\"integer\"}\n",
        "MAX_MEMORY_LENGTH = 100000 #@param {type:\"integer\"}\n",
        "Q_UPDATE_FREQUENCY = 5000 #@param {type:\"integer\"}\n",
        "\n",
        "# Pre Buffer Guidance\n",
        "WINDOW_SIZE = (104, 80)\n",
        "\n",
        "# Sub-Model Settings\n",
        "SLICE_ONE_NAME = \"s1_MAT_ImageClassifier_v3\" #@p\\aram {type:\"string\"}\n",
        "SLICE_ONE_TRAINABLE = True #@param {type:\"boolean\"}\n",
        "SLICE_ONE_CHECKPOINT = True #@param {type:\"boolean\"}\n",
        "\n",
        "SLICE_TWO_NAME = \"s2_MAT_ImageClassifier_v3\" #@param {type:\"string\"}\n",
        "SLICE_TWO_TRAINABLE = True #@param {type:\"boolean\"}\n",
        "SLICE_TWO_CHECKPOINT = True #@param {type:\"boolean\"}\n",
        "\n",
        "SLICE_THREE_NAME = \"s3_MAT_ImageClassifier_v3\" #@param {type:\"string\"}\n",
        "SLICE_THREE_TRAINABLE = True #@param {type:\"boolean\"}\n",
        "SLICE_THREE_CHECKPOINT = True #@param {type:\"boolean\"}\n",
        "\n",
        "FULL_MODEL_NAME = \"s2_MAT_Agent_Testing_v1\" #@param {type:\"string\"}\n",
        "FULL_MODEL_TRAINABLE = True #@param {type:\"boolean\"}\n",
        "FULL_MODEL_CHECKPOINT = False #@param {type:\"boolean\"}\n",
        "\n",
        "CHECKPOINT_FREQUENCY =  5000#@param {type:\"integer\"}\n",
        "\n",
        "SAVE_AGENT = False #@param {type:\"boolean\"}\n",
        "\n",
        "# ZIP_OUTPUT = True #@param {type:\"boolean\"}\n",
        "\n",
        "## Game selector feedback\n",
        "print(\"Selected Game: \" + ENVIRONMENT_NAME)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected Game: BreakoutNoFrameskip-v4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGIl3BKliih1"
      },
      "source": [
        "#### Setup Model Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFzeNuWrURPP"
      },
      "source": [
        "%%capture\n",
        "\n",
        "import os\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  COLAB = True\n",
        "  \n",
        "except:\n",
        "  !pip install gdown\n",
        "  COLAB = False\n",
        "\n",
        "model_dir = 'ISAR_Model_Data'\n",
        "data_dir = 'ISAR_Main_Classification'\n",
        "transfer_dir = 'ISAR_Sentiment_Transfer'\n",
        "\n",
        "\n",
        "if IMPORT_MAIN_DATA :\n",
        "    if not os.path.exists(data_dir): ## Make it if it doesn't exist\n",
        "      !gdown https://drive.google.com/uc?id=1P7o1x4ZpPbd16VQDwaMzllbN-tlfqqIH\n",
        "      !unzip ISAR_Main_Classification.zip\n",
        "      !rm ISAR_Main_Classification.zip\n",
        "if IMPORT_SENTIMENT_DATA:\n",
        "    if not os.path.exists(transfer_dir): ## Make it if it doesn't exist\n",
        "      !gdown https://drive.google.com/uc?id=1UDUNnw04q5cvms5ibM6pNn-wXtJphXxZ\n",
        "      !unzip ISAR_Sentiment_Transfer.zip\n",
        "      !rm ISAR_Sentiment_Transfer.zip\n",
        "if IMPORT_MODEL_DATA:\n",
        "    if not os.path.exists(model_dir): ## Make it if it doesn't exist\n",
        "      !gdown https://drive.google.com/uc?id=1IVw1bEAmMDiVeHfPPBWBfMj3h9WliumD\n",
        "      !unzip ISAR_Model_Data.zip\n",
        "      !rm ISAR_Model_Data.zip\n",
        "      "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poXz23gKsczB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f79f237-622b-4087-e2a5-3ed2e441a0d4"
      },
      "source": [
        "if CREATE_MISSING_DIRECTORIES:  \n",
        "  if not os.path.exists(data_dir): ## Make it if it doesn't exist\n",
        "    print(\"Creating Main Data Directory\")\n",
        "    os.makedirs(data_dir)\n",
        "  else:\n",
        "    print(\"Main Data Directory Found\")\n",
        "  if not os.path.exists(transfer_dir): ## Make it if it doesn't exist\n",
        "    print(\"Creating Transfer Data Directory\")\n",
        "    os.makedirs(transfer_dir)\n",
        "  else:\n",
        "    print(\"Transfer Data Directory Found\")\n",
        "  if not os.path.exists(model_dir): ## Make it if it doesn't exist\n",
        "    print(\"Creating Model Directory\")\n",
        "    os.makedirs(model_dir)\n",
        "  else:\n",
        "    print(\"Model Directory Found\")\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Main Data Directory Found\n",
            "Transfer Data Directory Found\n",
            "Model Directory Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNp06xZqiWKD"
      },
      "source": [
        "#### Setup Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjxfLJqifsa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d06c563-8c11-4b3c-fc79-4079062fbbd2"
      },
      "source": [
        "## Begin by importing . . .  oh . . . everything!\n",
        "try:\n",
        "  import math\n",
        "  import random\n",
        "  import numpy as np\n",
        "\n",
        "  import glob\n",
        "  import io\n",
        "  import base64\n",
        "  from time import sleep\n",
        "\n",
        "  from collections import deque\n",
        "\n",
        "  import gym\n",
        "  import tensorflow as tf\n",
        "  import tensorflow_hub as hub\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "  from tensorflow.keras.optimizers import Nadam, Adam\n",
        "  from tensorflow import keras\n",
        "\n",
        "  import matplotlib\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  from IPython.display import HTML\n",
        "  from IPython import display as ipythondisplay\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "except:\n",
        "  %%capture\n",
        "  if COLAB:\n",
        "    ## For colab we must install some dependancies\n",
        "    !apt-get install -y xvfb x11-utils\n",
        "    ## Next we will need to install a virtual display and correct Open AI installation\n",
        "    !pip install gym[all]==0.17.3\n",
        "    !pip install pyvirtualdisplay==0.2.* \n",
        "    !pip install PyOpenGL==3.1.* \n",
        "    !pip install PyOpenGL-accelerate==3.1.*\n",
        "    !pip install pyglet\n",
        "    # So let's setup the virtual display\n",
        "    import pyvirtualdisplay\n",
        "    # use False with Xvfb\n",
        "    _display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "    _ = _display.start()\n",
        "    # Now Check the Display\n",
        "    !echo $DISPLAY\n",
        "\n",
        "if USE_GPU_SUPPORT:\n",
        "  print(\"TF version:\", tf.__version__)\n",
        "  print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "  # Set Memory Growth\n",
        "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "  if gpus:\n",
        "    try:\n",
        "      # Currently, memory growth needs to be the same across GPUs\n",
        "      for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(gpu)\n",
        "      logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "      print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "      # Memory growth must be set before GPUs have been initialized\n",
        "      print(e)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.4.1\n",
            "Num GPUs Available:  1\n",
            "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdX2lI15iCvS"
      },
      "source": [
        "#### Setup Frame PreProcessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT-35yCogEXo"
      },
      "source": [
        "### Custom Pre-Processor\n",
        "# Stack frames and average on axis=-1 to produce a Single 210, 160, 1 greyscale image #old crop = img = frame[1:176:2, ::2]\n",
        "# Rescale to 104, 80, 1 then stack in three's (3) to produce a single RGB compatible representation of evironmental space-time\n",
        "class TFramePreBuffer:\n",
        "\n",
        "    def __init__(self, t_size=3, setting=0, scaling=1):\n",
        "        self.un_flicker_memory = []\n",
        "        self.temporal_memory = []\n",
        "        self.temporal_size = t_size\n",
        "        self.processor_setting = setting\n",
        "        self.scale = scaling\n",
        "\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        if self.scale == 0:\n",
        "            if self.processor_setting == 0:\n",
        "                return np.array(frame[1:209:2, ::2])*(1/255.0)\n",
        "\n",
        "            if self.processor_setting == 1:\n",
        "                while len(self.temporal_memory) < self.temporal_size:\n",
        "                    self.temporal_memory.append(frame[1:209:2, ::2].mean(axis=2,keepdims=True)) \n",
        "                temporal_image = np.concatenate((self.temporal_memory[0],\n",
        "                                                  self.temporal_memory[1],\n",
        "                                                  self.temporal_memory[2]), \n",
        "                                                axis=-1)*(1/255.0)\n",
        "                if len(self.temporal_memory) >= self.temporal_size:\n",
        "                    del self.temporal_memory[:1]\n",
        "                return temporal_image\n",
        "\n",
        "            if self.processor_setting == 2:\n",
        "                while len(self.un_flicker_memory) < 2:\n",
        "                    self.un_flicker_memory.append(frame[1:209:2, ::2])\n",
        "                while len(self.temporal_memory) < self.temporal_size:\n",
        "                    self.temporal_memory.append(np.concatenate((self.un_flicker_memory[0].mean(axis=2,keepdims=True),\n",
        "                                                                self.un_flicker_memory[1].mean(axis=2,keepdims=True)),\n",
        "                                                                axis=-1).max(axis=2))\n",
        "                temporal_image = np.concatenate(np.expand_dims((self.temporal_memory[0], \n",
        "                                                                self.temporal_memory[1], \n",
        "                                                                self.temporal_memory[2]), \n",
        "                                                              axis=-1), axis=-1)*(1/255.0)\n",
        "                if len(self.temporal_memory) >= self.temporal_size:\n",
        "                    del self.temporal_memory[:1]\n",
        "                return temporal_image\n",
        "\n",
        "\n",
        "        if self.scale == 1:\n",
        "            if self.processor_setting == 0:\n",
        "                return (np.array(frame[1:209:2, ::2])-128)*(1/128.0)\n",
        "\n",
        "            if self.processor_setting == 1:\n",
        "                while len(self.temporal_memory) < self.temporal_size:\n",
        "                    self.temporal_memory.append(frame[1:209:2, ::2].mean(axis=2,keepdims=True)) \n",
        "                temporal_image = (np.concatenate((self.temporal_memory[0],\n",
        "                                                  self.temporal_memory[1],\n",
        "                                                  self.temporal_memory[2]), \n",
        "                                                axis=-1)-128)*(1/128.0)\n",
        "                if len(self.temporal_memory) >= self.temporal_size:\n",
        "                    del self.temporal_memory[:1]\n",
        "                return temporal_image\n",
        "\n",
        "            if self.processor_setting == 2:\n",
        "                while len(self.un_flicker_memory) < 2:\n",
        "                    self.un_flicker_memory.append(frame[1:209:2, ::2])\n",
        "                while len(self.temporal_memory) < self.temporal_size:\n",
        "                    self.temporal_memory.append(np.concatenate((self.un_flicker_memory[0].mean(axis=2,keepdims=True),\n",
        "                                                                self.un_flicker_memory[1].mean(axis=2,keepdims=True)),\n",
        "                                                                axis=-1).max(axis=2))\n",
        "                temporal_image = (np.concatenate(np.expand_dims((self.temporal_memory[0], \n",
        "                                                                self.temporal_memory[1], \n",
        "                                                                self.temporal_memory[2]), \n",
        "                                                              axis=-1), axis=-1)-128)/128\n",
        "                if len(self.temporal_memory) >= self.temporal_size:\n",
        "                    del self.temporal_memory[:1]\n",
        "                return temporal_image\n",
        "\n",
        "\n",
        "#### Instantiate and call with\n",
        "# tFrame.process_frame(frame)\n",
        "\n",
        "## Resize Only\n",
        "# tFrame = TFramePreBuffer(t_size=3, setting=0, scaling=1)\n",
        "\n",
        "## Resize Grayscale and Stack Temporally\n",
        "tFrame = TFramePreBuffer(t_size=3, setting=1, scaling=1)\n",
        "\n",
        "# ## Resize Grayscale De-Flicker and Stack Temporally\n",
        "# tFrame = TFramePreBuffer(t_size=3, setting=2, scaling=1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vtDg55hojmL"
      },
      "source": [
        "#### Setup Progress Bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyqPA-frPMS1"
      },
      "source": [
        "class ChippieProgressBot:\n",
        "\n",
        "    def __init__(self, window_size=100, row_configuration=8):\n",
        "        self.rowCount = 0\n",
        "        self.miniScore = 0\n",
        "        self.movingAverage = []\n",
        "        self.windowSize = window_size\n",
        "        self.facelist1 = [\"~{0_0}~\",\"~{o_o}~\",\"~{o_0}~\",\"~{0_o}~\"]\n",
        "        self.row_configuration = row_configuration\n",
        "\n",
        "    def training(self, score):\n",
        "        if self.miniScore < score:\n",
        "            self.miniScore += 1\n",
        "            print(self.facelist1[int(self.miniScore % 4)] + str(int(score))+\"   \", end='')\n",
        "            self.rowCount += 1\n",
        "            if self.rowCount >= self.row_configuration:\n",
        "                print(\"\\n\")\n",
        "                self.rowCount = 0\n",
        "        else:\n",
        "           return\n",
        "\n",
        "\n",
        "    def q_update(self):\n",
        "        print(\"\"\"  {-_-}    \"\"\", end='')\n",
        "        self.rowCount += 1\n",
        "        if self.rowCount >= MAX_CHIPPIES_ROW:\n",
        "            print(\"\\n\")\n",
        "            self.rowCount = 0\n",
        "\n",
        "    def dead(self, score, totalScore, episode, completion_target,  survived, experiance, memory, epsilon):\n",
        "        \n",
        "        if len(self.movingAverage) >= self.windowSize:\n",
        "          del self.movingAverage[:1]\n",
        "        self.movingAverage.append(score)\n",
        "\n",
        "        print(\"\"\" `{x_X}~   \"\"\"+\"\\n\")\n",
        "\n",
        "        print(\"Episode: {}/{}, Episode Score: {}, Avg Episode Score: {:.4}, Survival Time: {}\"\n",
        "        .format(episode+1, completion_target, score, totalScore/(episode+1), survived)+\"\\n\")\n",
        "\n",
        "        print(\"\\{^,^}~\"+\"{:.3}\"\n",
        "        .format(sum(self.movingAverage)/len(self.movingAverage))+\"\\n\")\n",
        "\n",
        "        print(\"Total Steps: {}, Memory Size: {}, Current Epsilon Value: {:.2}\"\n",
        "        .format(experiance, memory, epsilon)+\"\\n\")\n",
        "\n",
        "        self.rowCount = 0\n",
        "        self.miniScore = 0\n",
        "\n",
        "\n",
        "     \n",
        "# chippie.training(score)\n",
        "chippie = ChippieProgressBot(window_size=100, row_configuration=MAX_CHIPPIES_ROW)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F5PijpNi9Wg"
      },
      "source": [
        "#### Define the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Nw-i27h9nR"
      },
      "source": [
        "class DQNAgent:\n",
        "\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        \n",
        "        self.state_memory = []\n",
        "        self.action_memory = []\n",
        "        self.reward_memory = []\n",
        "        self.next_state_memory = []\n",
        "        self.done_memory = [] \n",
        "        \n",
        "        self.update_rate = Q_UPDATE_FREQUENCY # Number of steps until updating the target network\n",
        "\n",
        "        self.gamma = agent_gamma # decay or discount rate\n",
        "\n",
        "        self.epsilon = agent_epsilon # exploration rate\n",
        "        self.epsilon_decay = agent_epsilon_decay # exploration decay\n",
        "        self.epsilon_min = agent_epsilon_min # min exploration\n",
        "\n",
        "        self.learning_rate = agent_learning_rate # SGD or Nadam rate param\n",
        "\n",
        "        # self.model, self.sliceOne, self.sliceTwo, self.sliceThree = self._build_new_model()\n",
        "        # self.target_model, self.target_sliceOne, self.target_sliceTwo, self.target_sliceThree = self._build_new_model()\n",
        "\n",
        "        # self.model, self.sliceOne, self.sliceTwo, self.sliceThree = self._build_1S_transfer_model()\n",
        "        # self.target_model, self.target_sliceOne, self.target_sliceTwo, self.target_sliceThree = self._build_1S_transfer_model()\n",
        "\n",
        "        self.model, self.sliceOne, self.sliceTwo, self.sliceThree = self._build_2S_transfer_model()\n",
        "        self.target_model, self.target_sliceOne, self.target_sliceTwo, self.target_sliceThree = self._build_2S_transfer_model()\n",
        "\n",
        "        # self.model, self.sliceOne, self.sliceTwo, self.sliceThree = self._build_3S_transfer_model()\n",
        "        # self.target_model, self.target_sliceOne, self.target_sliceTwo, self.target_sliceThree = self._build_3S_transfer_model()\n",
        "\n",
        "        self.target_model.set_weights(self.model.get_weights()) # create Q-target network\n",
        "        \n",
        "        self.model.summary()\n",
        "\n",
        "  \n",
        "    def _build_new_model(self): # private method\n",
        "        # Slice One\n",
        "        s1_input_layer = tf.keras.Input(shape=WINDOW_SIZE + (3,))\n",
        "        s1_conv1 = tf.keras.layers.Conv2D(32, kernel_size=(8, 8),strides=4, activation='relu', name='S1_Conv1', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s1_input_layer)\n",
        "        s1_output = tf.keras.layers.Conv2D(64, kernel_size=(4, 4),strides=2, activation='relu', name='S1_Conv2', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s1_conv1)\n",
        "        s1_model = tf.keras.Model(inputs=s1_input_layer, outputs=s1_output)\n",
        "        # s1_model.summary()\n",
        "\n",
        "       # Slice Two\n",
        "        s2_input_layer = tf.keras.Input(shape=(11, 8, 64))\n",
        "        s2_conv1 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3),strides=1, activation='relu', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s2_input_layer)\n",
        "        s2_flat_1 = tf.keras.layers.Flatten(name='S2_Flat1')(s2_conv1)\n",
        "        s2_output = tf.keras.layers.Dense(512, activation='relu', name='s2_Dense_1', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s2_flat_1)\n",
        "        s2_model = tf.keras.Model(inputs=s2_input_layer, outputs=s2_output)\n",
        "        s2_model._name = SLICE_TWO_NAME\n",
        "        # s2_model.summary()\n",
        "\n",
        "        # Slice Three\n",
        "        s3_input_layer = tf.keras.Input(shape=(512))\n",
        "        s3_output = tf.keras.layers.Dense(self.action_size, activation='linear', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s3_input_layer)\n",
        "        s3_model = tf.keras.Model(inputs=s3_input_layer, outputs=s3_output)\n",
        "        s3_model._name = SLICE_THREE_NAME\n",
        "        # s3_model.summary()\n",
        "\n",
        "        full_model_input = tf.keras.Input(shape=(WINDOW_SIZE+(3,)))\n",
        "        s1_pass = s1_model(full_model_input) #, training=False)\n",
        "        s2_pass = s2_model(s1_pass)\n",
        "        s3_final_output = s3_model(s2_pass)\n",
        "\n",
        "        \n",
        "        full_model = tf.keras.Model(inputs=full_model_input, outputs=s3_final_output)\n",
        "        full_model._name = FULL_MODEL_NAME\n",
        "        # full_model.summary()\n",
        "\n",
        "        s1_model.trainable = SLICE_ONE_TRAINABLE # ref param above\n",
        "        s2_model.trainable = SLICE_TWO_TRAINABLE # ref param above\n",
        "        s3_model.trainable = SLICE_THREE_TRAINABLE # ref param above\n",
        "        full_model.trainable = FULL_MODEL_TRAINABLE # ref param above\n",
        "        \n",
        "        # # Using Nadam because its awesome\n",
        "        self.optimizer = keras.optimizers.Nadam(learning_rate=self.learning_rate, clipnorm=1.0)\n",
        "        # # Using Huber loss for stability\n",
        "        self.loss_function = keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
        "        \n",
        "        return full_model, s1_model, s2_model, s3_model\n",
        "        \n",
        "\n",
        "    def _build_1S_transfer_model(self): # private method    \n",
        "\n",
        "        # Slice One\n",
        "        s1_input_layer = tf.keras.Input(shape=WINDOW_SIZE + (3,))\n",
        "        s1_model = tf.keras.models.load_model(model_dir + '/' + SLICE_ONE_NAME)\n",
        "        s1_model._name = SLICE_ONE_NAME\n",
        "        # s1_model.summary()\n",
        "\n",
        "        # Slice Two\n",
        "        s2_input_layer = tf.keras.Input(shape=(11, 8, 64))\n",
        "        s2_conv1 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3),strides=1, activation='relu', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s2_input_layer)\n",
        "        s2_flat_1 = tf.keras.layers.Flatten(name='S2_Flat1')(s2_conv1)\n",
        "        s2_output = tf.keras.layers.Dense(512, activation='relu', name='s2_Dense_1', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s2_flat_1)\n",
        "        s2_model = tf.keras.Model(inputs=s2_input_layer, outputs=s2_output)\n",
        "        s2_model._name = SLICE_TWO_NAME\n",
        "        # s2_model.summary()\n",
        "\n",
        "        # Slice Three\n",
        "        s3_input_layer = tf.keras.Input(shape=(512))\n",
        "        s3_output = tf.keras.layers.Dense(self.action_size, activation='linear', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s3_input_layer)\n",
        "        s3_model = tf.keras.Model(inputs=s3_input_layer, outputs=s3_output)\n",
        "        s3_model._name = SLICE_THREE_NAME\n",
        "        # s3_model.summary()\n",
        "\n",
        "        full_model_input = tf.keras.Input(shape=(WINDOW_SIZE+(3,)))\n",
        "        s1_pass = s1_model(full_model_input) #, training=False)\n",
        "        s2_pass = s2_model(s1_pass)\n",
        "        s3_final_output = s3_model(s2_pass)\n",
        "\n",
        "        \n",
        "        full_model = tf.keras.Model(inputs=full_model_input, outputs=s3_final_output)\n",
        "        full_model._name = FULL_MODEL_NAME\n",
        "        # full_model.summary()\n",
        "\n",
        "        s1_model.trainable = SLICE_ONE_TRAINABLE # ref param above\n",
        "        s2_model.trainable = SLICE_TWO_TRAINABLE # ref param above\n",
        "        s3_model.trainable = SLICE_THREE_TRAINABLE # ref param above\n",
        "        full_model.trainable = FULL_MODEL_TRAINABLE # ref param above\n",
        "        \n",
        "        # # Using Nadam because its awesome\n",
        "        self.optimizer = keras.optimizers.Nadam(learning_rate=self.learning_rate, clipnorm=1.0)\n",
        "        # # Using Huber loss for stability\n",
        "        self.loss_function = keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
        "        \n",
        "        return full_model, s1_model, s2_model, s3_model\n",
        "\n",
        "\n",
        "    def _build_2S_transfer_model(self): # private method    \n",
        "\n",
        "        # Slice One\n",
        "        s1_input_layer = tf.keras.Input(shape=WINDOW_SIZE + (3,))\n",
        "        s1_model = tf.keras.models.load_model(model_dir + '/' + SLICE_ONE_NAME)\n",
        "        s1_model._name = SLICE_ONE_NAME\n",
        "        # s1_model.summary()\n",
        "\n",
        "        # Slice Two\n",
        "        s2_input_layer = tf.keras.Input(shape=(11, 8, 64))\n",
        "        s2_model = tf.keras.models.load_model(model_dir + '/' + SLICE_TWO_NAME)\n",
        "        s2_model._name = SLICE_TWO_NAME\n",
        "        # s2_model.summary()\n",
        "\n",
        "        # Slice Three\n",
        "        s3_input_layer = tf.keras.Input(shape=(512))\n",
        "        s3_output = tf.keras.layers.Dense(self.action_size, activation='linear', \\\n",
        "                                    kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0))(s3_input_layer)\n",
        "        s3_model = tf.keras.Model(inputs=s3_input_layer, outputs=s3_output)\n",
        "        s3_model._name = SLICE_THREE_NAME\n",
        "        # s3_model.summary()\n",
        "\n",
        "        full_model_input = tf.keras.Input(shape=(WINDOW_SIZE+(3,)))\n",
        "        s1_pass = s1_model(full_model_input) #, training=False)\n",
        "        s2_pass = s2_model(s1_pass)\n",
        "        s3_final_output = s3_model(s2_pass)\n",
        "\n",
        "        \n",
        "        full_model = tf.keras.Model(inputs=full_model_input, outputs=s3_final_output)\n",
        "        full_model._name = FULL_MODEL_NAME\n",
        "        # full_model.summary()\n",
        "\n",
        "        s1_model.trainable = SLICE_ONE_TRAINABLE # ref param above\n",
        "        s2_model.trainable = SLICE_TWO_TRAINABLE # ref param above\n",
        "        s3_model.trainable = SLICE_THREE_TRAINABLE # ref param above\n",
        "        full_model.trainable = FULL_MODEL_TRAINABLE # ref param above\n",
        "        \n",
        "        # # Using Nadam because its awesome\n",
        "        self.optimizer = keras.optimizers.Nadam(learning_rate=self.learning_rate, clipnorm=1.0)\n",
        "        # # Using Huber loss for stability\n",
        "        self.loss_function = keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
        "        \n",
        "        return full_model, s1_model, s2_model, s3_model\n",
        "\n",
        "\n",
        "    def _build_3S_transfer_model(self): # private method    \n",
        "\n",
        "        # Slice One\n",
        "        s1_input_layer = tf.keras.Input(shape=WINDOW_SIZE + (3,))\n",
        "        s1_model = tf.keras.models.load_model(model_dir + '/' + SLICE_ONE_NAME)\n",
        "        s1_model._name = SLICE_ONE_NAME\n",
        "        # s1_model.summary()\n",
        "\n",
        "        # Slice Two\n",
        "        s2_input_layer = tf.keras.Input(shape=(11, 8, 64))\n",
        "        s2_model = tf.keras.models.load_model(model_dir + '/' + SLICE_TWO_NAME)\n",
        "        s2_model._name = SLICE_TWO_NAME\n",
        "        # s2_model.summary()\n",
        "\n",
        "        # Slice Three                                   #### ndim 4?\n",
        "        s3_input_layer = tf.keras.Input(shape=(512))\n",
        "        s3_model = tf.keras.models.load_model(model_dir + '/' + SLICE_THREE_NAME)\n",
        "        s3_model._name = SLICE_THREE_NAME\n",
        "        # s3_model.summary()\n",
        "\n",
        "        full_model_input = tf.keras.Input(shape=(WINDOW_SIZE+(3,)))\n",
        "        s1_pass = s1_model(full_model_input) #, training=False)\n",
        "        s2_pass = s2_model(s1_pass)\n",
        "        s3_final_output = s3_model(s2_pass)\n",
        "\n",
        "        \n",
        "        full_model = tf.keras.Model(inputs=full_model_input, outputs=s3_final_output)\n",
        "        full_model._name = FULL_MODEL_NAME\n",
        "        # full_model.summary()\n",
        "\n",
        "        s1_model.trainable = SLICE_ONE_TRAINABLE # ref param above\n",
        "        s2_model.trainable = SLICE_TWO_TRAINABLE # ref param above\n",
        "        s3_model.trainable = SLICE_THREE_TRAINABLE # ref param above\n",
        "        full_model.trainable = FULL_MODEL_TRAINABLE # ref param above\n",
        "        \n",
        "        # # Using Nadam because its awesome\n",
        "        self.optimizer = keras.optimizers.Nadam(learning_rate=self.learning_rate, clipnorm=1.0)\n",
        "        # # Using Huber loss for stability\n",
        "        self.loss_function = keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
        "        \n",
        "        return full_model, s1_model, s2_model, s3_model\n",
        "\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        # My newly implemented memory, Hopefully it makes us faster\n",
        "        self.state_memory.append(state)\n",
        "        self.action_memory.append(action)\n",
        "        self.reward_memory.append(reward)\n",
        "        self.next_state_memory.append(next_state)\n",
        "        self.done_memory.append(done)\n",
        "        if len(self.reward_memory) > MAX_MEMORY_LENGTH:\n",
        "            del self.reward_memory[:1]\n",
        "            del self.state_memory[:1]\n",
        "            del self.next_state_memory[:1]\n",
        "            del self.action_memory[:1]\n",
        "            del self.done_memory[:1]\n",
        "\n",
        "    def train(self, batch_size): # method that trains agent model\n",
        "\n",
        "        ### The New Implementation\n",
        "        idx = np.random.choice(range(len(self.reward_memory)), size=batch_size)\n",
        "\n",
        "        state_batch = np.array([self.state_memory[i] for i in idx])\n",
        "        action_batch = [self.action_memory[i] for i in idx]\n",
        "        reward_batch = [self.reward_memory[i] for i in idx]\n",
        "        next_state_batch = np.array([self.next_state_memory[i] for i in idx])\n",
        "        done_batch = tf.convert_to_tensor([float(self.done_memory[i]) for i in idx])\n",
        "        \n",
        "        ## This is where all the magic happens\n",
        "        qValueF = self.target_model.predict(next_state_batch) # approximate future reward\n",
        "\n",
        "        qValueUpdate = reward_batch + self.gamma * tf.reduce_max(qValueF, axis=1)\n",
        "\n",
        "        qValueUpdate = qValueUpdate * (1 - done_batch) - done_batch\n",
        "\n",
        "        oneHotMask = tf.one_hot(action_batch, self.action_size)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Train the model on the states and updated Q-values\n",
        "            OqValue = self.model(state_batch)\n",
        "\n",
        "            # Apply the masks to the Q-values to get the Q-value for action taken\n",
        "            OqValue_action = tf.reduce_sum(tf.multiply(OqValue, oneHotMask), axis=1)\n",
        "\n",
        "            # Calculate loss between new Q-value and old Q-value\n",
        "            loss = self.loss_function(qValueUpdate, OqValue_action)\n",
        "\n",
        "        if DIAGNOSTIC_MODE:\n",
        "          print(\"Q-Values: \", qValueF[1])\n",
        "          print(\"Q-Values Update: \", qValueUpdate[1])\n",
        "          print(\"Masked Update:   \", oneHotMask[1])\n",
        "          print(\"Old Activations: \", OqValue[1])\n",
        "\n",
        "        # Backpropagation\n",
        "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "\n",
        "        if DIAGNOSTIC_MODE:\n",
        "          newQ = self.model.predict_step(state_batch)\n",
        "          print(\"New Activations: \", newQ[1], \"\\n\")\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon: \n",
        "            return random.randrange(self.action_size) # Do something stupid! (i.e. take a random action)\n",
        "        action_values = self.model(tf.expand_dims(tf.convert_to_tensor(state), 0), training=False)\n",
        "        return tf.argmax(action_values[0]).numpy()\n",
        "\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "    \n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(name)\n",
        "\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw2g6PjZPS9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d035c50-dec1-451b-e6c7-b0148b661b28"
      },
      "source": [
        "# Make Environment\n",
        "env = gym.make(ENVIRONMENT_NAME)\n",
        "state_size = (105, 80, 3)\n",
        "action_size = env.action_space.n\n",
        "\n",
        "## Intialize Our Agent\n",
        "agent = DQNAgent(state_size, action_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"s2_MAT_Agent_Testing_v1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 104, 80, 3)]      0         \n",
            "_________________________________________________________________\n",
            "s1_MAT_ImageClassifier_v3 (F (None, 11, 8, 64)         39008     \n",
            "_________________________________________________________________\n",
            "s2_MAT_ImageClassifier_v3 (F (None, 512)               1806912   \n",
            "_________________________________________________________________\n",
            "s3_MAT_ImageClassifier_v3 (F (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 1,847,972\n",
            "Trainable params: 1,847,972\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z5loBrJiHON"
      },
      "source": [
        "#### Define Training Loop Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8cbu_VJh-E4"
      },
      "source": [
        "def myPlayground():\n",
        "\n",
        "  # Empty Rewards Counter\n",
        "  reward = 0\n",
        "  all_rewards = 0\n",
        "  total_time = 0\n",
        "  done = False\n",
        "  \n",
        "  # Display in Colab\n",
        "  if COLAB:\n",
        "      if RENDER == True:\n",
        "          done, ax = plt.subplots(1, 1)\n",
        "          img = ax.imshow(env.render('rgb_array'))    \n",
        "\n",
        "  # Make Some Starting data\n",
        "  state = tFrame.process_frame(env.reset()) # Reset state for new episode\n",
        "  while len(agent.reward_memory) < STARTING_MEMORY_SIZE:\n",
        "    action = random.randrange(agent.action_size)\n",
        "    next_frame, reward, done, _ = env.step(action) # Agent sends action to env wrapper and gets feedback\n",
        "    next_state = tFrame.process_frame(next_frame)\n",
        "    if reward > 0.0: # Check and modify reward\n",
        "      reward = 1.0\n",
        "    if reward < 0.0:\n",
        "      reward = -1.0\n",
        "    if done:\n",
        "      reward = -1.0\n",
        "    agent.remember(state, action, reward, next_state, done) # Store sequence in replay memory\n",
        "    state = next_state # Update state\n",
        "    if done:\n",
        "      state = tFrame.process_frame(env.reset())\n",
        "\n",
        "\n",
        "  # Training Loop\n",
        "  for e in range(n_episodes): ## Go Eat Cherries\n",
        "      \n",
        "      done = False\n",
        "      time = 0\n",
        "      game_score = 0\n",
        "      reward = 0\n",
        "\n",
        "      state = tFrame.process_frame(env.reset()) # Reset state for new episode\n",
        "      \n",
        "      for skip in range(skip_start): # Skip the start of each game\n",
        "          env.step(0)\n",
        "\n",
        "      while not done:\n",
        "      \n",
        "          time += 1\n",
        "          total_time += 1\n",
        "\n",
        "          # Display\n",
        "          if RENDER:\n",
        "              if COLAB:\n",
        "                  img.set_data(env.render(mode='rgb_array')) \n",
        "                  ax.axis('off')\n",
        "                  ipythondisplay.display(plt.gcf())\n",
        "                  ipythondisplay.clear_output(wait=True)\n",
        "              else:\n",
        "                  env.render()\n",
        "                  if OBSERVATION_MODE:\n",
        "                      sleep(0.02)\n",
        "\n",
        "          # Update Target Network\n",
        "          if total_time % agent.update_rate == 0:\n",
        "              agent.update_target_model()\n",
        "              if CHIPPIE_PROGESS_REPORTS:\n",
        "                chippie.q_update()\n",
        "\n",
        "          # Transition Dynamics\n",
        "          action = agent.act(state) # Get action from agent\n",
        "          next_frame, reward, done, _ = env.step(action) # Agent sends action to env wrapper and gets feedback\n",
        "          next_state = tFrame.process_frame(next_frame)\n",
        "          \n",
        "          # Sternly Validate Reward\n",
        "          if reward > 0.0: \n",
        "            reward = 1.0\n",
        "            game_score += reward\n",
        "          if reward < 0.0:\n",
        "            reward = -1.0\n",
        "          if done:\n",
        "            reward = -1.0\n",
        "            all_rewards += game_score\n",
        "            if CHIPPIE_PROGESS_REPORTS:\n",
        "              chippie.dead(score=game_score, totalScore=all_rewards, episode=e, completion_target=n_episodes, survived=time, \n",
        "                           experiance=total_time, memory=len(agent.reward_memory), epsilon=agent.epsilon)\n",
        "            agent.remember(state, action, reward, next_state, done) # Store death in replay memory\n",
        "            break\n",
        "\n",
        "          agent.remember(state, action, reward, next_state, done) # Store sequence in replay memory\n",
        "          state = next_state # Update state\n",
        "\n",
        "          if len(agent.reward_memory) > STARTING_MEMORY_SIZE:\n",
        "            if not OBSERVATION_MODE:\n",
        "              if total_time % action_steps == 0:\n",
        "                agent.train(BATCH_SIZE)\n",
        "                if CHIPPIE_PROGESS_REPORTS:\n",
        "                  chippie.training(game_score)\n",
        "\n",
        "      if e % CHECKPOINT_FREQUENCY == 0 and len(agent.reward_memory) > STARTING_MEMORY_SIZE:\n",
        "        if SLICE_ONE_CHECKPOINT:\n",
        "            saved_model_path = model_dir + \"/ISAR_Production_Models/\" + ENVIRONMENT_NAME + SLICE_ONE_NAME + '{:08d}'.format(e) \n",
        "            tf.saved_model.save(agent.sliceOne, saved_model_path)\n",
        "\n",
        "        if SLICE_TWO_CHECKPOINT:\n",
        "            saved_model_path = model_dir + \"/ISAR_Production_Models/\" + ENVIRONMENT_NAME + SLICE_TWO_NAME + '{:08d}'.format(e) \n",
        "            tf.saved_model.save(agent.sliceTwo, saved_model_path)\n",
        "        \n",
        "        if SLICE_THREE_CHECKPOINT:\n",
        "            saved_model_path = model_dir + \"/ISAR_Production_Models/\" + ENVIRONMENT_NAME + SLICE_TWO_NAME + '{:08d}'.format(e) \n",
        "            tf.saved_model.save(agent.sliceTwo, saved_model_path)\n",
        "\n",
        "        if FULL_MODEL_CHECKPOINT:\n",
        "            saved_model_path = model_dir + \"/ISAR_Production_Models/\" + ENVIRONMENT_NAME + FULL_MODEL_NAME + '{:08d}'.format(e) \n",
        "            tf.saved_model.save(agent.model, saved_model_path)\n",
        "\n",
        "        if SAVE_AGENT:\n",
        "            agent.save(model_dir+ \"/ISAR_Production_Models/\" + ENVIRONMENT_NAME + FULL_MODEL_NAME + \"agent_weights_\" + '{:08d}'.format(e) +\".hdf5\")\n",
        "      print(\"\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgI4QKIOo6Nl"
      },
      "source": [
        "#### Interactive Playground (runs automatically)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i9UWy2w5nUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b22b71-7817-4be5-cba0-09ea6152c564"
      },
      "source": [
        "#### Run From Bottom (Can be run with one click)\n",
        "## # agent.epsilon = 0.999\n",
        "myPlayground()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " `{x_X}~   \n",
            "\n",
            "Episode: 1/25000, Episode Score: 0, Avg Episode Score: 0.0, Survival Time: 502\n",
            "\n",
            "\\{^,^}~0.0\n",
            "\n",
            "Total Steps: 502, Memory Size: 25501, Current Epsilon Value: 0.99\n",
            "\n",
            "INFO:tensorflow:Assets written to: ISAR_Model_Data/ISAR_Production_Models/BreakoutNoFrameskip-v4s1_MAT_ImageClassifier_v300000000/assets\n",
            "INFO:tensorflow:Assets written to: ISAR_Model_Data/ISAR_Production_Models/BreakoutNoFrameskip-v4s2_MAT_ImageClassifier_v300000000/assets\n",
            "INFO:tensorflow:Assets written to: ISAR_Model_Data/ISAR_Production_Models/BreakoutNoFrameskip-v4s2_MAT_ImageClassifier_v300000000/assets\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 2/25000, Episode Score: 0, Avg Episode Score: 0.0, Survival Time: 490\n",
            "\n",
            "\\{^,^}~0.0\n",
            "\n",
            "Total Steps: 992, Memory Size: 25991, Current Epsilon Value: 0.98\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 3/25000, Episode Score: 2.0, Avg Episode Score: 0.6667, Survival Time: 877\n",
            "\n",
            "\\{^,^}~0.667\n",
            "\n",
            "Total Steps: 1869, Memory Size: 26868, Current Epsilon Value: 0.95\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 4/25000, Episode Score: 0, Avg Episode Score: 0.5, Survival Time: 494\n",
            "\n",
            "\\{^,^}~0.5\n",
            "\n",
            "Total Steps: 2363, Memory Size: 27362, Current Epsilon Value: 0.94\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 5/25000, Episode Score: 3.0, Avg Episode Score: 1.0, Survival Time: 931\n",
            "\n",
            "\\{^,^}~1.0\n",
            "\n",
            "Total Steps: 3294, Memory Size: 28293, Current Epsilon Value: 0.92\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 6/25000, Episode Score: 2.0, Avg Episode Score: 1.167, Survival Time: 806\n",
            "\n",
            "\\{^,^}~1.17\n",
            "\n",
            "Total Steps: 4100, Memory Size: 29099, Current Epsilon Value: 0.9\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 7/25000, Episode Score: 1.0, Avg Episode Score: 1.143, Survival Time: 614\n",
            "\n",
            "\\{^,^}~1.14\n",
            "\n",
            "Total Steps: 4714, Memory Size: 29713, Current Epsilon Value: 0.89\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 8/25000, Episode Score: 2.0, Avg Episode Score: 1.25, Survival Time: 797\n",
            "\n",
            "\\{^,^}~1.25\n",
            "\n",
            "Total Steps: 5511, Memory Size: 30510, Current Epsilon Value: 0.87\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 9/25000, Episode Score: 0, Avg Episode Score: 1.111, Survival Time: 503\n",
            "\n",
            "\\{^,^}~1.11\n",
            "\n",
            "Total Steps: 6014, Memory Size: 31013, Current Epsilon Value: 0.86\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 10/25000, Episode Score: 1.0, Avg Episode Score: 1.1, Survival Time: 616\n",
            "\n",
            "\\{^,^}~1.1\n",
            "\n",
            "Total Steps: 6630, Memory Size: 31629, Current Epsilon Value: 0.85\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 11/25000, Episode Score: 4.0, Avg Episode Score: 1.364, Survival Time: 1185\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 7815, Memory Size: 32814, Current Epsilon Value: 0.82\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 12/25000, Episode Score: 2.0, Avg Episode Score: 1.417, Survival Time: 874\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 8689, Memory Size: 33688, Current Epsilon Value: 0.8\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 13/25000, Episode Score: 2.0, Avg Episode Score: 1.462, Survival Time: 805\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 9494, Memory Size: 34493, Current Epsilon Value: 0.79\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 14/25000, Episode Score: 1.0, Avg Episode Score: 1.429, Survival Time: 677\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 10171, Memory Size: 35170, Current Epsilon Value: 0.78\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 15/25000, Episode Score: 2.0, Avg Episode Score: 1.467, Survival Time: 715\n",
            "\n",
            "\\{^,^}~1.47\n",
            "\n",
            "Total Steps: 10886, Memory Size: 35885, Current Epsilon Value: 0.76\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 16/25000, Episode Score: 4.0, Avg Episode Score: 1.625, Survival Time: 1190\n",
            "\n",
            "\\{^,^}~1.62\n",
            "\n",
            "Total Steps: 12076, Memory Size: 37075, Current Epsilon Value: 0.74\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 17/25000, Episode Score: 1.0, Avg Episode Score: 1.588, Survival Time: 613\n",
            "\n",
            "\\{^,^}~1.59\n",
            "\n",
            "Total Steps: 12689, Memory Size: 37688, Current Epsilon Value: 0.73\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 18/25000, Episode Score: 3.0, Avg Episode Score: 1.667, Survival Time: 982\n",
            "\n",
            "\\{^,^}~1.67\n",
            "\n",
            "Total Steps: 13671, Memory Size: 38670, Current Epsilon Value: 0.71\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 19/25000, Episode Score: 0, Avg Episode Score: 1.579, Survival Time: 503\n",
            "\n",
            "\\{^,^}~1.58\n",
            "\n",
            "Total Steps: 14174, Memory Size: 39173, Current Epsilon Value: 0.7\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 20/25000, Episode Score: 0, Avg Episode Score: 1.5, Survival Time: 510\n",
            "\n",
            "\\{^,^}~1.5\n",
            "\n",
            "Total Steps: 14684, Memory Size: 39683, Current Epsilon Value: 0.69\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 21/25000, Episode Score: 2.0, Avg Episode Score: 1.524, Survival Time: 747\n",
            "\n",
            "\\{^,^}~1.52\n",
            "\n",
            "Total Steps: 15431, Memory Size: 40430, Current Epsilon Value: 0.68\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 22/25000, Episode Score: 2.0, Avg Episode Score: 1.545, Survival Time: 905\n",
            "\n",
            "\\{^,^}~1.55\n",
            "\n",
            "Total Steps: 16336, Memory Size: 41335, Current Epsilon Value: 0.67\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 23/25000, Episode Score: 1.0, Avg Episode Score: 1.522, Survival Time: 679\n",
            "\n",
            "\\{^,^}~1.52\n",
            "\n",
            "Total Steps: 17015, Memory Size: 42014, Current Epsilon Value: 0.65\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 24/25000, Episode Score: 0, Avg Episode Score: 1.458, Survival Time: 491\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 17506, Memory Size: 42505, Current Epsilon Value: 0.65\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 25/25000, Episode Score: 2.0, Avg Episode Score: 1.48, Survival Time: 813\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 18319, Memory Size: 43318, Current Epsilon Value: 0.63\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 26/25000, Episode Score: 0, Avg Episode Score: 1.423, Survival Time: 505\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 18824, Memory Size: 43823, Current Epsilon Value: 0.62\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 27/25000, Episode Score: 4.0, Avg Episode Score: 1.519, Survival Time: 1188\n",
            "\n",
            "\\{^,^}~1.52\n",
            "\n",
            "Total Steps: 20012, Memory Size: 45011, Current Epsilon Value: 0.61\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 28/25000, Episode Score: 2.0, Avg Episode Score: 1.536, Survival Time: 791\n",
            "\n",
            "\\{^,^}~1.54\n",
            "\n",
            "Total Steps: 20803, Memory Size: 45802, Current Epsilon Value: 0.59\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 29/25000, Episode Score: 0, Avg Episode Score: 1.483, Survival Time: 502\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 21305, Memory Size: 46304, Current Epsilon Value: 0.59\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 30/25000, Episode Score: 0, Avg Episode Score: 1.433, Survival Time: 509\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 21814, Memory Size: 46813, Current Epsilon Value: 0.58\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 31/25000, Episode Score: 0, Avg Episode Score: 1.387, Survival Time: 497\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 22311, Memory Size: 47310, Current Epsilon Value: 0.57\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 32/25000, Episode Score: 2.0, Avg Episode Score: 1.406, Survival Time: 887\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 23198, Memory Size: 48197, Current Epsilon Value: 0.56\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 33/25000, Episode Score: 2.0, Avg Episode Score: 1.424, Survival Time: 809\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 24007, Memory Size: 49006, Current Epsilon Value: 0.55\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 34/25000, Episode Score: 2.0, Avg Episode Score: 1.441, Survival Time: 831\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 24838, Memory Size: 49837, Current Epsilon Value: 0.54\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 35/25000, Episode Score: 3.0, Avg Episode Score: 1.486, Survival Time: 976\n",
            "\n",
            "\\{^,^}~1.49\n",
            "\n",
            "Total Steps: 25814, Memory Size: 50813, Current Epsilon Value: 0.52\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 36/25000, Episode Score: 2.0, Avg Episode Score: 1.5, Survival Time: 798\n",
            "\n",
            "\\{^,^}~1.5\n",
            "\n",
            "Total Steps: 26612, Memory Size: 51611, Current Epsilon Value: 0.51\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 37/25000, Episode Score: 0, Avg Episode Score: 1.459, Survival Time: 498\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 27110, Memory Size: 52109, Current Epsilon Value: 0.51\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 38/25000, Episode Score: 3.0, Avg Episode Score: 1.5, Survival Time: 994\n",
            "\n",
            "\\{^,^}~1.5\n",
            "\n",
            "Total Steps: 28104, Memory Size: 53103, Current Epsilon Value: 0.5\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 39/25000, Episode Score: 1.0, Avg Episode Score: 1.487, Survival Time: 681\n",
            "\n",
            "\\{^,^}~1.49\n",
            "\n",
            "Total Steps: 28785, Memory Size: 53784, Current Epsilon Value: 0.49\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 40/25000, Episode Score: 1.0, Avg Episode Score: 1.475, Survival Time: 686\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 29471, Memory Size: 54470, Current Epsilon Value: 0.48\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 41/25000, Episode Score: 0, Avg Episode Score: 1.439, Survival Time: 502\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 29973, Memory Size: 54972, Current Epsilon Value: 0.47\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 42/25000, Episode Score: 0, Avg Episode Score: 1.405, Survival Time: 490\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 30463, Memory Size: 55462, Current Epsilon Value: 0.47\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 43/25000, Episode Score: 1.0, Avg Episode Score: 1.395, Survival Time: 713\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 31176, Memory Size: 56175, Current Epsilon Value: 0.46\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 44/25000, Episode Score: 1.0, Avg Episode Score: 1.386, Survival Time: 694\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 31870, Memory Size: 56869, Current Epsilon Value: 0.45\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 45/25000, Episode Score: 2.0, Avg Episode Score: 1.4, Survival Time: 816\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 32686, Memory Size: 57685, Current Epsilon Value: 0.44\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 46/25000, Episode Score: 0, Avg Episode Score: 1.37, Survival Time: 514\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 33200, Memory Size: 58199, Current Epsilon Value: 0.44\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 47/25000, Episode Score: 1.0, Avg Episode Score: 1.362, Survival Time: 631\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 33831, Memory Size: 58830, Current Epsilon Value: 0.43\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 48/25000, Episode Score: 1.0, Avg Episode Score: 1.354, Survival Time: 629\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 34460, Memory Size: 59459, Current Epsilon Value: 0.42\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 49/25000, Episode Score: 3.0, Avg Episode Score: 1.388, Survival Time: 921\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 35381, Memory Size: 60380, Current Epsilon Value: 0.41\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 50/25000, Episode Score: 1.0, Avg Episode Score: 1.38, Survival Time: 711\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 36092, Memory Size: 61091, Current Epsilon Value: 0.41\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 51/25000, Episode Score: 1.0, Avg Episode Score: 1.373, Survival Time: 629\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 36721, Memory Size: 61720, Current Epsilon Value: 0.4\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 52/25000, Episode Score: 1.0, Avg Episode Score: 1.365, Survival Time: 723\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 37444, Memory Size: 62443, Current Epsilon Value: 0.39\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 53/25000, Episode Score: 2.0, Avg Episode Score: 1.377, Survival Time: 787\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 38231, Memory Size: 63230, Current Epsilon Value: 0.39\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 54/25000, Episode Score: 0, Avg Episode Score: 1.352, Survival Time: 528\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 38759, Memory Size: 63758, Current Epsilon Value: 0.38\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 55/25000, Episode Score: 2.0, Avg Episode Score: 1.364, Survival Time: 833\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 39592, Memory Size: 64591, Current Epsilon Value: 0.37\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 56/25000, Episode Score: 2.0, Avg Episode Score: 1.375, Survival Time: 843\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 40435, Memory Size: 65434, Current Epsilon Value: 0.36\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 57/25000, Episode Score: 1.0, Avg Episode Score: 1.368, Survival Time: 714\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 41149, Memory Size: 66148, Current Epsilon Value: 0.36\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 58/25000, Episode Score: 4.0, Avg Episode Score: 1.414, Survival Time: 1299\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 42448, Memory Size: 67447, Current Epsilon Value: 0.35\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 59/25000, Episode Score: 2.0, Avg Episode Score: 1.424, Survival Time: 899\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 43347, Memory Size: 68346, Current Epsilon Value: 0.34\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 60/25000, Episode Score: 2.0, Avg Episode Score: 1.433, Survival Time: 794\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 44141, Memory Size: 69140, Current Epsilon Value: 0.33\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 61/25000, Episode Score: 0, Avg Episode Score: 1.41, Survival Time: 547\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 44688, Memory Size: 69687, Current Epsilon Value: 0.33\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 62/25000, Episode Score: 2.0, Avg Episode Score: 1.419, Survival Time: 895\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 45583, Memory Size: 70582, Current Epsilon Value: 0.32\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 63/25000, Episode Score: 4.0, Avg Episode Score: 1.46, Survival Time: 1088\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 46671, Memory Size: 71670, Current Epsilon Value: 0.31\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 64/25000, Episode Score: 1.0, Avg Episode Score: 1.453, Survival Time: 638\n",
            "\n",
            "\\{^,^}~1.45\n",
            "\n",
            "Total Steps: 47309, Memory Size: 72308, Current Epsilon Value: 0.31\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 65/25000, Episode Score: 0, Avg Episode Score: 1.431, Survival Time: 501\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 47810, Memory Size: 72809, Current Epsilon Value: 0.3\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 66/25000, Episode Score: 0, Avg Episode Score: 1.409, Survival Time: 500\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 48310, Memory Size: 73309, Current Epsilon Value: 0.3\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 67/25000, Episode Score: 0, Avg Episode Score: 1.388, Survival Time: 526\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 48836, Memory Size: 73835, Current Epsilon Value: 0.3\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 68/25000, Episode Score: 0, Avg Episode Score: 1.368, Survival Time: 525\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 49361, Memory Size: 74360, Current Epsilon Value: 0.29\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 69/25000, Episode Score: 3.0, Avg Episode Score: 1.391, Survival Time: 933\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 50294, Memory Size: 75293, Current Epsilon Value: 0.28\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 70/25000, Episode Score: 2.0, Avg Episode Score: 1.4, Survival Time: 816\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 51110, Memory Size: 76109, Current Epsilon Value: 0.28\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 71/25000, Episode Score: 1.0, Avg Episode Score: 1.394, Survival Time: 732\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 51842, Memory Size: 76841, Current Epsilon Value: 0.27\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 72/25000, Episode Score: 0, Avg Episode Score: 1.375, Survival Time: 500\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 52342, Memory Size: 77341, Current Epsilon Value: 0.27\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 73/25000, Episode Score: 0, Avg Episode Score: 1.356, Survival Time: 509\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 52851, Memory Size: 77850, Current Epsilon Value: 0.27\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 74/25000, Episode Score: 4.0, Avg Episode Score: 1.392, Survival Time: 1176\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 54027, Memory Size: 79026, Current Epsilon Value: 0.26\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 75/25000, Episode Score: 0, Avg Episode Score: 1.373, Survival Time: 493\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 54520, Memory Size: 79519, Current Epsilon Value: 0.26\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 76/25000, Episode Score: 1.0, Avg Episode Score: 1.368, Survival Time: 701\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 55221, Memory Size: 80220, Current Epsilon Value: 0.25\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 77/25000, Episode Score: 2.0, Avg Episode Score: 1.377, Survival Time: 810\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 56031, Memory Size: 81030, Current Epsilon Value: 0.25\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 78/25000, Episode Score: 0, Avg Episode Score: 1.359, Survival Time: 526\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 56557, Memory Size: 81556, Current Epsilon Value: 0.24\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 79/25000, Episode Score: 0, Avg Episode Score: 1.342, Survival Time: 526\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 57083, Memory Size: 82082, Current Epsilon Value: 0.24\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 80/25000, Episode Score: 1.0, Avg Episode Score: 1.337, Survival Time: 742\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 57825, Memory Size: 82824, Current Epsilon Value: 0.24\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 81/25000, Episode Score: 0, Avg Episode Score: 1.321, Survival Time: 504\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 58329, Memory Size: 83328, Current Epsilon Value: 0.23\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 82/25000, Episode Score: 0, Avg Episode Score: 1.305, Survival Time: 503\n",
            "\n",
            "\\{^,^}~1.3\n",
            "\n",
            "Total Steps: 58832, Memory Size: 83831, Current Epsilon Value: 0.23\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 83/25000, Episode Score: 1.0, Avg Episode Score: 1.301, Survival Time: 697\n",
            "\n",
            "\\{^,^}~1.3\n",
            "\n",
            "Total Steps: 59529, Memory Size: 84528, Current Epsilon Value: 0.23\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 84/25000, Episode Score: 1.0, Avg Episode Score: 1.298, Survival Time: 688\n",
            "\n",
            "\\{^,^}~1.3\n",
            "\n",
            "Total Steps: 60217, Memory Size: 85216, Current Epsilon Value: 0.22\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 85/25000, Episode Score: 3.0, Avg Episode Score: 1.318, Survival Time: 956\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 61173, Memory Size: 86172, Current Epsilon Value: 0.22\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 86/25000, Episode Score: 0, Avg Episode Score: 1.302, Survival Time: 507\n",
            "\n",
            "\\{^,^}~1.3\n",
            "\n",
            "Total Steps: 61680, Memory Size: 86679, Current Epsilon Value: 0.21\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 87/25000, Episode Score: 3.0, Avg Episode Score: 1.322, Survival Time: 1023\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 62703, Memory Size: 87702, Current Epsilon Value: 0.21\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 88/25000, Episode Score: 2.0, Avg Episode Score: 1.33, Survival Time: 909\n",
            "\n",
            "\\{^,^}~1.33\n",
            "\n",
            "Total Steps: 63612, Memory Size: 88611, Current Epsilon Value: 0.2\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 89/25000, Episode Score: 0, Avg Episode Score: 1.315, Survival Time: 517\n",
            "\n",
            "\\{^,^}~1.31\n",
            "\n",
            "Total Steps: 64129, Memory Size: 89128, Current Epsilon Value: 0.2\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 90/25000, Episode Score: 0, Avg Episode Score: 1.3, Survival Time: 515\n",
            "\n",
            "\\{^,^}~1.3\n",
            "\n",
            "Total Steps: 64644, Memory Size: 89643, Current Epsilon Value: 0.2\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 91/25000, Episode Score: 1.0, Avg Episode Score: 1.297, Survival Time: 726\n",
            "\n",
            "\\{^,^}~1.3\n",
            "\n",
            "Total Steps: 65370, Memory Size: 90369, Current Epsilon Value: 0.2\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 92/25000, Episode Score: 1.0, Avg Episode Score: 1.293, Survival Time: 742\n",
            "\n",
            "\\{^,^}~1.29\n",
            "\n",
            "Total Steps: 66112, Memory Size: 91111, Current Epsilon Value: 0.19\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 93/25000, Episode Score: 3.0, Avg Episode Score: 1.312, Survival Time: 1051\n",
            "\n",
            "\\{^,^}~1.31\n",
            "\n",
            "Total Steps: 67163, Memory Size: 92162, Current Epsilon Value: 0.19\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 94/25000, Episode Score: 2.0, Avg Episode Score: 1.319, Survival Time: 826\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 67989, Memory Size: 92988, Current Epsilon Value: 0.18\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 95/25000, Episode Score: 1.0, Avg Episode Score: 1.316, Survival Time: 641\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 68630, Memory Size: 93629, Current Epsilon Value: 0.18\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 96/25000, Episode Score: 3.0, Avg Episode Score: 1.333, Survival Time: 977\n",
            "\n",
            "\\{^,^}~1.33\n",
            "\n",
            "Total Steps: 69607, Memory Size: 94606, Current Epsilon Value: 0.18\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 97/25000, Episode Score: 0, Avg Episode Score: 1.32, Survival Time: 528\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 70135, Memory Size: 95134, Current Epsilon Value: 0.17\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 98/25000, Episode Score: 4.0, Avg Episode Score: 1.347, Survival Time: 1211\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 71346, Memory Size: 96345, Current Epsilon Value: 0.17\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 99/25000, Episode Score: 2.0, Avg Episode Score: 1.354, Survival Time: 828\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 72174, Memory Size: 97173, Current Epsilon Value: 0.16\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 100/25000, Episode Score: 0, Avg Episode Score: 1.34, Survival Time: 520\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 72694, Memory Size: 97693, Current Epsilon Value: 0.16\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 101/25000, Episode Score: 1.0, Avg Episode Score: 1.337, Survival Time: 785\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 73479, Memory Size: 98478, Current Epsilon Value: 0.16\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 102/25000, Episode Score: 1.0, Avg Episode Score: 1.333, Survival Time: 703\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 74182, Memory Size: 99181, Current Epsilon Value: 0.16\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 103/25000, Episode Score: 1.0, Avg Episode Score: 1.33, Survival Time: 617\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 74799, Memory Size: 99798, Current Epsilon Value: 0.15\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 104/25000, Episode Score: 0, Avg Episode Score: 1.317, Survival Time: 534\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 75333, Memory Size: 100000, Current Epsilon Value: 0.15\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 105/25000, Episode Score: 4.0, Avg Episode Score: 1.343, Survival Time: 1212\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 76545, Memory Size: 100000, Current Epsilon Value: 0.15\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 106/25000, Episode Score: 1.0, Avg Episode Score: 1.34, Survival Time: 732\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 77277, Memory Size: 100000, Current Epsilon Value: 0.15\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 107/25000, Episode Score: 0, Avg Episode Score: 1.327, Survival Time: 525\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 77802, Memory Size: 100000, Current Epsilon Value: 0.14\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 108/25000, Episode Score: 2.0, Avg Episode Score: 1.333, Survival Time: 899\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 78701, Memory Size: 100000, Current Epsilon Value: 0.14\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 109/25000, Episode Score: 0, Avg Episode Score: 1.321, Survival Time: 548\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 79249, Memory Size: 100000, Current Epsilon Value: 0.14\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 110/25000, Episode Score: 0, Avg Episode Score: 1.309, Survival Time: 491\n",
            "\n",
            "\\{^,^}~1.33\n",
            "\n",
            "Total Steps: 79740, Memory Size: 100000, Current Epsilon Value: 0.14\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 111/25000, Episode Score: 3.0, Avg Episode Score: 1.324, Survival Time: 1092\n",
            "\n",
            "\\{^,^}~1.32\n",
            "\n",
            "Total Steps: 80832, Memory Size: 100000, Current Epsilon Value: 0.13\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4   ~{o_o}~5   ~{o_0}~6   ~{0_o}~7    `{x_X}~   \n",
            "\n",
            "Episode: 112/25000, Episode Score: 7.0, Avg Episode Score: 1.375, Survival Time: 1773\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 82605, Memory Size: 100000, Current Epsilon Value: 0.13\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 113/25000, Episode Score: 2.0, Avg Episode Score: 1.381, Survival Time: 848\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 83453, Memory Size: 100000, Current Epsilon Value: 0.12\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 114/25000, Episode Score: 2.0, Avg Episode Score: 1.386, Survival Time: 805\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 84258, Memory Size: 100000, Current Epsilon Value: 0.12\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 115/25000, Episode Score: 3.0, Avg Episode Score: 1.4, Survival Time: 1010\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 85268, Memory Size: 100000, Current Epsilon Value: 0.12\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 116/25000, Episode Score: 3.0, Avg Episode Score: 1.414, Survival Time: 1051\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 86319, Memory Size: 100000, Current Epsilon Value: 0.12\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 117/25000, Episode Score: 1.0, Avg Episode Score: 1.41, Survival Time: 682\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 87001, Memory Size: 100000, Current Epsilon Value: 0.11\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 118/25000, Episode Score: 1.0, Avg Episode Score: 1.407, Survival Time: 717\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 87718, Memory Size: 100000, Current Epsilon Value: 0.11\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 119/25000, Episode Score: 2.0, Avg Episode Score: 1.412, Survival Time: 800\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 88518, Memory Size: 100000, Current Epsilon Value: 0.11\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4   ~{o_o}~5    `{x_X}~   \n",
            "\n",
            "Episode: 120/25000, Episode Score: 5.0, Avg Episode Score: 1.442, Survival Time: 1411\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 89929, Memory Size: 100000, Current Epsilon Value: 0.11\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 121/25000, Episode Score: 0, Avg Episode Score: 1.43, Survival Time: 487\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 90416, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 122/25000, Episode Score: 1.0, Avg Episode Score: 1.426, Survival Time: 677\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 91093, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 123/25000, Episode Score: 0, Avg Episode Score: 1.415, Survival Time: 556\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 91649, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 124/25000, Episode Score: 2.0, Avg Episode Score: 1.419, Survival Time: 835\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 92484, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 125/25000, Episode Score: 1.0, Avg Episode Score: 1.416, Survival Time: 697\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 93181, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 126/25000, Episode Score: 2.0, Avg Episode Score: 1.421, Survival Time: 808\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 93989, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 127/25000, Episode Score: 2.0, Avg Episode Score: 1.425, Survival Time: 932\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 94921, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 128/25000, Episode Score: 3.0, Avg Episode Score: 1.438, Survival Time: 1160\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 96081, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 129/25000, Episode Score: 2.0, Avg Episode Score: 1.442, Survival Time: 808\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 96889, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 130/25000, Episode Score: 1.0, Avg Episode Score: 1.438, Survival Time: 647\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 97536, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 131/25000, Episode Score: 0, Avg Episode Score: 1.427, Survival Time: 518\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 98054, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 132/25000, Episode Score: 2.0, Avg Episode Score: 1.432, Survival Time: 740\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 98794, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 133/25000, Episode Score: 1.0, Avg Episode Score: 1.429, Survival Time: 663\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 99457, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 134/25000, Episode Score: 1.0, Avg Episode Score: 1.425, Survival Time: 715\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 100172, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 135/25000, Episode Score: 2.0, Avg Episode Score: 1.43, Survival Time: 870\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 101042, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 136/25000, Episode Score: 1.0, Avg Episode Score: 1.426, Survival Time: 661\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 101703, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 137/25000, Episode Score: 1.0, Avg Episode Score: 1.423, Survival Time: 684\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 102387, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 138/25000, Episode Score: 0, Avg Episode Score: 1.413, Survival Time: 559\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 102946, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 139/25000, Episode Score: 0, Avg Episode Score: 1.403, Survival Time: 671\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 103617, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 140/25000, Episode Score: 2.0, Avg Episode Score: 1.407, Survival Time: 981\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 104598, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 141/25000, Episode Score: 2.0, Avg Episode Score: 1.411, Survival Time: 806\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 105404, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 142/25000, Episode Score: 1.0, Avg Episode Score: 1.408, Survival Time: 657\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 106061, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 143/25000, Episode Score: 1.0, Avg Episode Score: 1.406, Survival Time: 706\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 106767, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 144/25000, Episode Score: 3.0, Avg Episode Score: 1.417, Survival Time: 1023\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 107790, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 145/25000, Episode Score: 1.0, Avg Episode Score: 1.414, Survival Time: 722\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 108512, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 146/25000, Episode Score: 1.0, Avg Episode Score: 1.411, Survival Time: 741\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 109253, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 147/25000, Episode Score: 2.0, Avg Episode Score: 1.415, Survival Time: 874\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 110127, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 148/25000, Episode Score: 1.0, Avg Episode Score: 1.412, Survival Time: 726\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 110853, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 149/25000, Episode Score: 0, Avg Episode Score: 1.403, Survival Time: 532\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 111385, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 150/25000, Episode Score: 0, Avg Episode Score: 1.393, Survival Time: 516\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 111901, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4   ~{o_o}~5    `{x_X}~   \n",
            "\n",
            "Episode: 151/25000, Episode Score: 5.0, Avg Episode Score: 1.417, Survival Time: 1406\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 113307, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 152/25000, Episode Score: 0, Avg Episode Score: 1.408, Survival Time: 538\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 113845, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 153/25000, Episode Score: 1.0, Avg Episode Score: 1.405, Survival Time: 777\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 114622, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 154/25000, Episode Score: 1.0, Avg Episode Score: 1.403, Survival Time: 634\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 115256, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 155/25000, Episode Score: 1.0, Avg Episode Score: 1.4, Survival Time: 684\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 115940, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 156/25000, Episode Score: 1.0, Avg Episode Score: 1.397, Survival Time: 676\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 116616, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 157/25000, Episode Score: 1.0, Avg Episode Score: 1.395, Survival Time: 766\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 117382, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 158/25000, Episode Score: 3.0, Avg Episode Score: 1.405, Survival Time: 1015\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 118397, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 159/25000, Episode Score: 2.0, Avg Episode Score: 1.409, Survival Time: 924\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 119321, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 160/25000, Episode Score: 1.0, Avg Episode Score: 1.406, Survival Time: 724\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 120045, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 161/25000, Episode Score: 1.0, Avg Episode Score: 1.404, Survival Time: 710\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 120755, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 162/25000, Episode Score: 0, Avg Episode Score: 1.395, Survival Time: 530\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 121285, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 163/25000, Episode Score: 0, Avg Episode Score: 1.387, Survival Time: 550\n",
            "\n",
            "\\{^,^}~1.34\n",
            "\n",
            "Total Steps: 121835, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 164/25000, Episode Score: 2.0, Avg Episode Score: 1.39, Survival Time: 942\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 122777, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 165/25000, Episode Score: 3.0, Avg Episode Score: 1.4, Survival Time: 1095\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 123872, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 166/25000, Episode Score: 1.0, Avg Episode Score: 1.398, Survival Time: 677\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 124549, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 167/25000, Episode Score: 0, Avg Episode Score: 1.389, Survival Time: 532\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 125081, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 168/25000, Episode Score: 2.0, Avg Episode Score: 1.393, Survival Time: 906\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 125987, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 169/25000, Episode Score: 0, Avg Episode Score: 1.385, Survival Time: 504\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 126491, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 170/25000, Episode Score: 1.0, Avg Episode Score: 1.382, Survival Time: 746\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 127237, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 171/25000, Episode Score: 0, Avg Episode Score: 1.374, Survival Time: 520\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 127757, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 172/25000, Episode Score: 2.0, Avg Episode Score: 1.378, Survival Time: 861\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 128618, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 173/25000, Episode Score: 1.0, Avg Episode Score: 1.376, Survival Time: 739\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 129357, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 174/25000, Episode Score: 2.0, Avg Episode Score: 1.379, Survival Time: 912\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 130269, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 175/25000, Episode Score: 1.0, Avg Episode Score: 1.377, Survival Time: 668\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 130937, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 176/25000, Episode Score: 1.0, Avg Episode Score: 1.375, Survival Time: 763\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 131700, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 177/25000, Episode Score: 2.0, Avg Episode Score: 1.379, Survival Time: 872\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 132572, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 178/25000, Episode Score: 3.0, Avg Episode Score: 1.388, Survival Time: 988\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 133560, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 179/25000, Episode Score: 1.0, Avg Episode Score: 1.385, Survival Time: 689\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 134249, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 180/25000, Episode Score: 2.0, Avg Episode Score: 1.389, Survival Time: 884\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 135133, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 181/25000, Episode Score: 1.0, Avg Episode Score: 1.387, Survival Time: 775\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 135908, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 182/25000, Episode Score: 0, Avg Episode Score: 1.379, Survival Time: 617\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 136525, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 183/25000, Episode Score: 2.0, Avg Episode Score: 1.383, Survival Time: 868\n",
            "\n",
            "\\{^,^}~1.45\n",
            "\n",
            "Total Steps: 137393, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 184/25000, Episode Score: 2.0, Avg Episode Score: 1.386, Survival Time: 924\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 138317, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 185/25000, Episode Score: 0, Avg Episode Score: 1.378, Survival Time: 556\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 138873, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 186/25000, Episode Score: 1.0, Avg Episode Score: 1.376, Survival Time: 748\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 139621, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 187/25000, Episode Score: 1.0, Avg Episode Score: 1.374, Survival Time: 630\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 140251, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 188/25000, Episode Score: 1.0, Avg Episode Score: 1.372, Survival Time: 622\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 140873, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 189/25000, Episode Score: 2.0, Avg Episode Score: 1.376, Survival Time: 964\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 141837, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 190/25000, Episode Score: 0, Avg Episode Score: 1.368, Survival Time: 538\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 142375, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 191/25000, Episode Score: 4.0, Avg Episode Score: 1.382, Survival Time: 1254\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 143629, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 192/25000, Episode Score: 4.0, Avg Episode Score: 1.396, Survival Time: 1058\n",
            "\n",
            "\\{^,^}~1.49\n",
            "\n",
            "Total Steps: 144687, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 193/25000, Episode Score: 3.0, Avg Episode Score: 1.404, Survival Time: 928\n",
            "\n",
            "\\{^,^}~1.49\n",
            "\n",
            "Total Steps: 145615, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 194/25000, Episode Score: 1.0, Avg Episode Score: 1.402, Survival Time: 651\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 146266, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 195/25000, Episode Score: 1.0, Avg Episode Score: 1.4, Survival Time: 727\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 146993, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 196/25000, Episode Score: 1.0, Avg Episode Score: 1.398, Survival Time: 698\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 147691, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 197/25000, Episode Score: 2.0, Avg Episode Score: 1.401, Survival Time: 846\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 148537, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 198/25000, Episode Score: 0, Avg Episode Score: 1.394, Survival Time: 576\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 149113, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 199/25000, Episode Score: 2.0, Avg Episode Score: 1.397, Survival Time: 743\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 149856, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1     {-_-}    ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 200/25000, Episode Score: 2.0, Avg Episode Score: 1.4, Survival Time: 801\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 150657, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 201/25000, Episode Score: 1.0, Avg Episode Score: 1.398, Survival Time: 664\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 151321, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 202/25000, Episode Score: 1.0, Avg Episode Score: 1.396, Survival Time: 638\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 151959, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 203/25000, Episode Score: 1.0, Avg Episode Score: 1.394, Survival Time: 718\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 152677, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 204/25000, Episode Score: 1.0, Avg Episode Score: 1.392, Survival Time: 621\n",
            "\n",
            "\\{^,^}~1.47\n",
            "\n",
            "Total Steps: 153298, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 205/25000, Episode Score: 4.0, Avg Episode Score: 1.405, Survival Time: 1179\n",
            "\n",
            "\\{^,^}~1.47\n",
            "\n",
            "Total Steps: 154477, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 206/25000, Episode Score: 0, Avg Episode Score: 1.398, Survival Time: 540\n",
            "\n",
            "\\{^,^}~1.46\n",
            "\n",
            "Total Steps: 155017, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 207/25000, Episode Score: 4.0, Avg Episode Score: 1.411, Survival Time: 1178\n",
            "\n",
            "\\{^,^}~1.5\n",
            "\n",
            "Total Steps: 156195, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 208/25000, Episode Score: 0, Avg Episode Score: 1.404, Survival Time: 586\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 156781, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 209/25000, Episode Score: 2.0, Avg Episode Score: 1.407, Survival Time: 796\n",
            "\n",
            "\\{^,^}~1.5\n",
            "\n",
            "Total Steps: 157577, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 210/25000, Episode Score: 3.0, Avg Episode Score: 1.414, Survival Time: 1155\n",
            "\n",
            "\\{^,^}~1.53\n",
            "\n",
            "Total Steps: 158732, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 211/25000, Episode Score: 1.0, Avg Episode Score: 1.412, Survival Time: 634\n",
            "\n",
            "\\{^,^}~1.51\n",
            "\n",
            "Total Steps: 159366, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 212/25000, Episode Score: 1.0, Avg Episode Score: 1.41, Survival Time: 767\n",
            "\n",
            "\\{^,^}~1.45\n",
            "\n",
            "Total Steps: 160133, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 213/25000, Episode Score: 1.0, Avg Episode Score: 1.408, Survival Time: 721\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 160854, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 214/25000, Episode Score: 1.0, Avg Episode Score: 1.407, Survival Time: 703\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 161557, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 215/25000, Episode Score: 1.0, Avg Episode Score: 1.405, Survival Time: 827\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 162384, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 216/25000, Episode Score: 1.0, Avg Episode Score: 1.403, Survival Time: 639\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 163023, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 217/25000, Episode Score: 3.0, Avg Episode Score: 1.41, Survival Time: 1004\n",
            "\n",
            "\\{^,^}~1.41\n",
            "\n",
            "Total Steps: 164027, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 218/25000, Episode Score: 0, Avg Episode Score: 1.404, Survival Time: 546\n",
            "\n",
            "\\{^,^}~1.4\n",
            "\n",
            "Total Steps: 164573, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 219/25000, Episode Score: 0, Avg Episode Score: 1.397, Survival Time: 538\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 165111, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 220/25000, Episode Score: 2.0, Avg Episode Score: 1.4, Survival Time: 852\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 165963, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 221/25000, Episode Score: 0, Avg Episode Score: 1.394, Survival Time: 510\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 166473, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 222/25000, Episode Score: 3.0, Avg Episode Score: 1.401, Survival Time: 867\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 167340, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 223/25000, Episode Score: 1.0, Avg Episode Score: 1.399, Survival Time: 714\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 168054, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 224/25000, Episode Score: 1.0, Avg Episode Score: 1.397, Survival Time: 779\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 168833, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 225/25000, Episode Score: 2.0, Avg Episode Score: 1.4, Survival Time: 835\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 169668, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 226/25000, Episode Score: 1.0, Avg Episode Score: 1.398, Survival Time: 807\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 170475, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 227/25000, Episode Score: 1.0, Avg Episode Score: 1.396, Survival Time: 734\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 171209, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 228/25000, Episode Score: 2.0, Avg Episode Score: 1.399, Survival Time: 837\n",
            "\n",
            "\\{^,^}~1.35\n",
            "\n",
            "Total Steps: 172046, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 229/25000, Episode Score: 0, Avg Episode Score: 1.393, Survival Time: 555\n",
            "\n",
            "\\{^,^}~1.33\n",
            "\n",
            "Total Steps: 172601, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4   ~{o_o}~5    `{x_X}~   \n",
            "\n",
            "Episode: 230/25000, Episode Score: 5.0, Avg Episode Score: 1.409, Survival Time: 1293\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 173894, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 231/25000, Episode Score: 0, Avg Episode Score: 1.403, Survival Time: 667\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 174561, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}    ~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 232/25000, Episode Score: 1.0, Avg Episode Score: 1.401, Survival Time: 695\n",
            "\n",
            "\\{^,^}~1.36\n",
            "\n",
            "Total Steps: 175256, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 233/25000, Episode Score: 3.0, Avg Episode Score: 1.408, Survival Time: 1057\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 176313, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 234/25000, Episode Score: 2.0, Avg Episode Score: 1.41, Survival Time: 854\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 177167, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 235/25000, Episode Score: 1.0, Avg Episode Score: 1.409, Survival Time: 684\n",
            "\n",
            "\\{^,^}~1.38\n",
            "\n",
            "Total Steps: 177851, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 236/25000, Episode Score: 0, Avg Episode Score: 1.403, Survival Time: 585\n",
            "\n",
            "\\{^,^}~1.37\n",
            "\n",
            "Total Steps: 178436, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 237/25000, Episode Score: 3.0, Avg Episode Score: 1.409, Survival Time: 1097\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 179533, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "  {-_-}     `{x_X}~   \n",
            "\n",
            "Episode: 238/25000, Episode Score: 0, Avg Episode Score: 1.403, Survival Time: 578\n",
            "\n",
            "\\{^,^}~1.39\n",
            "\n",
            "Total Steps: 180111, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 239/25000, Episode Score: 3.0, Avg Episode Score: 1.41, Survival Time: 1129\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 181240, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4    `{x_X}~   \n",
            "\n",
            "Episode: 240/25000, Episode Score: 4.0, Avg Episode Score: 1.421, Survival Time: 1151\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 182391, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 241/25000, Episode Score: 0, Avg Episode Score: 1.415, Survival Time: 526\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 182917, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 242/25000, Episode Score: 1.0, Avg Episode Score: 1.413, Survival Time: 707\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 183624, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   ~{0_o}~3   ~{0_0}~4   ~{o_o}~5   ~{o_0}~6     {-_-}    ~{0_o}~7   \n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 243/25000, Episode Score: 7.0, Avg Episode Score: 1.436, Survival Time: 1721\n",
            "\n",
            "\\{^,^}~1.48\n",
            "\n",
            "Total Steps: 185345, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 244/25000, Episode Score: 0, Avg Episode Score: 1.43, Survival Time: 748\n",
            "\n",
            "\\{^,^}~1.45\n",
            "\n",
            "Total Steps: 186093, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 245/25000, Episode Score: 0, Avg Episode Score: 1.424, Survival Time: 561\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 186654, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 246/25000, Episode Score: 2.0, Avg Episode Score: 1.427, Survival Time: 907\n",
            "\n",
            "\\{^,^}~1.45\n",
            "\n",
            "Total Steps: 187561, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 247/25000, Episode Score: 0, Avg Episode Score: 1.421, Survival Time: 500\n",
            "\n",
            "\\{^,^}~1.43\n",
            "\n",
            "Total Steps: 188061, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 248/25000, Episode Score: 0, Avg Episode Score: 1.415, Survival Time: 509\n",
            "\n",
            "\\{^,^}~1.42\n",
            "\n",
            "Total Steps: 188570, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 249/25000, Episode Score: 2.0, Avg Episode Score: 1.418, Survival Time: 863\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 189433, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2     {-_-}    ~{0_o}~3    `{x_X}~   \n",
            "\n",
            "Episode: 250/25000, Episode Score: 3.0, Avg Episode Score: 1.424, Survival Time: 958\n",
            "\n",
            "\\{^,^}~1.47\n",
            "\n",
            "Total Steps: 190391, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2    `{x_X}~   \n",
            "\n",
            "Episode: 251/25000, Episode Score: 2.0, Avg Episode Score: 1.426, Survival Time: 911\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 191302, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1    `{x_X}~   \n",
            "\n",
            "Episode: 252/25000, Episode Score: 1.0, Avg Episode Score: 1.425, Survival Time: 736\n",
            "\n",
            "\\{^,^}~1.45\n",
            "\n",
            "Total Steps: 192038, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            " `{x_X}~   \n",
            "\n",
            "Episode: 253/25000, Episode Score: 0, Avg Episode Score: 1.419, Survival Time: 513\n",
            "\n",
            "\\{^,^}~1.44\n",
            "\n",
            "Total Steps: 192551, Memory Size: 100000, Current Epsilon Value: 0.1\n",
            "\n",
            "\n",
            "~{o_o}~1   ~{o_0}~2   "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8r9t3hNQCf3"
      },
      "source": [
        "#### Notes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vd_hkdb8R6d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}